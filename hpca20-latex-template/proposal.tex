\documentclass[pageno]{jpaper}


\usepackage[normalem]{ulem}

\begin{document}

\title{
18-740 Fall 2013 Research Proposal: Tournament Prefetcher}
\author{Ryan Macdonald \and Edward Sears}

\date{}
\maketitle

\thispagestyle{empty}

\begin{abstract}
In this paper, we will propose a plan to research the performance 
benefits of a hybrid tournament style prefetcher. We define the problem,
describe how our solution improves upon the current state of prefetcher
design, formally state our hypothesis, and describe the planned 
methodology of our research.
\end{abstract}

\section{The Problem}

Prefetching is a memory latency tolerance mechanism which aims to anticipate 
accesses to cache blocks and speculatively issue memory requests to those blocks with 
the intent of warming the cache for future execution. There are various types of prefetching 
strategies used in modern processors including stream, next-block, and Markov prefetchers. 
While each of these prefetching strategies has its advantages, none of them are optimal 
for all memory access patterns and workloads. See table 1. For example, a stream-based strategy may 
provide accurate, timely prefetches for a streaming access pattern, but it would underperform 
in the case of a more random, noncontiguous access pattern. Thus, modern processors require 
a more general purpose, hybrid prefetching mechanism to preserve optimal memory latency 
tolerance over a variety of memory demands within and between applications.


\section{Novelty}

Research has been conducted towards continuously monitoring prefetcher metrics including 
accuracy, timeliness, and cache pollution~\cite{srinath07}; based on these measurements, prefetch behavior 
can be tuned and optimized by hardware at run-time. While this research has had success 
in that it is able to dynamically optimize prefetch aggression, it falls short in that 
it does not attempt to dynamically change its fundamental prefetching strategy. This research 
will be novel in that it will attempt to dynamically determine an optimal prefetching 
strategy(stream, next-block, Markov, etc.) over changing memory demands. 

\section{Idea}

Our idea is to design, implement, and analyze the advantages and disadvantages of a hybrid, 
tournament prefetching mechanism which determines an optimal prefetching strategy at run-time 
based on the memory access pattern of the application currently running. One area of analysis 
will be which types of hardware prefetchers (stream, next-block, Markov, etc.) perform best 
together when placed in configuration with each other. A question this research will seek to 
answer is, “From M possible prefetching strategies, which N are optimal to include in a 
hybrid configuration?”

\section{Hypothesis}

We hypothesize that a prefetcher which dynamically takes into account performance metrics 
and tunes its strategy accordingly will outperform the accuracy, timeliness, and cache-pollutant 
behavior of a static, non-hybrid alternative. We anticipate that such a hybrid, tournament 
prefetcher will perform akin to the optimal static prefetching strategy for any given workload.

\section{Methodology}

In order to evaluate our hypothesis, we will need to extensively modify an existing processor 
simulator to model static and dynamic prefetching strategies. We plan to model and measure the 
accuracy, timeliness, and cache-pollutant behavior of the baseline simulator without prefetching, 
with each static prefetching strategy individually, and with various configurations of a hybrid, 
tournament prefetcher.

Modeling and measuring these metrics with each respective static prefetching mechanism should be 
relatively straightforward because they have already been documented and implemented~\cite{srinath07}, however, 
modeling the hybrid tournament prefetcher will be a bit more complicated. Our current design is 
that the hybrid prefetcher will instantiate various static prefetchers as well as a prediction unit, 
responsible for determining the optimal static prefetcher to use at any given time. This prediction unit 
will consist of a hardware structure which contains a speculative cache (s-cache) for each prefetcher 
strategy, keeping track of what the accuracy, timeliness, and cache blocks would be if the respective 
strategy had been used. The prediction unit will be updated in real time during program execution and, 
in this fashion, the optimal prefetching mechanism will be tracked. Thus, only one prefetcher will be 
issuing fetches to memory at a time; the others will merely be keeping track of what fetches they would’ve 
issued and updating their state accordingly.

We also wish to investigate how such a hybrid prefetcher could be integrated with previously explored throttling 
techniques. As a means to this end we hope to acquire, study, and modify the simulator used for this research~\cite{srinath07}.

\newpage
\section{Plan for final report}


\begin{table}[h!]
  \centering
  \begin{tabular}{|l|l|}
    \hline
    \textbf{Milestone} & \textbf{Expected Progress}\\
    \hline
    \hline
    1 & Finalized design for hybrid, \\
        &tournament prefetcher; implemented, \\
        &simulated, and benchmarked baseline, \\
        &static prefetchers.\\
    \hline
    2 & Implemented, simulated and \\
        &benchmarked hybrid, tournament \\
        &prefetcher; begin putting together\\
        &final results, data, report and \\
        &presentation.\\
    \hline
    Final Report & Integrate analysis of \\
                    &"best N static prefetchers"\\
                    &question and feedback \\
                    &directed throttling.\\
    \hline
    Moonshot goals & Implement hybrid prefetcher in RTL,\\
                    &use design compiler (DC) tools \\
                    &to further analyze performance, \\
                    &area, power, scalability;\\
                    &investigate possible use of ISA \\
                    &extensions and pragmas to \\
                    &explicitly allow the programmer to\\
                    &specify optimal prefetch strategy.\\
    \hline
  \end{tabular}
  \label{table:formatting}
\end{table}



\bstctlcite{bstctl:etal, bstctl:nodash, bstctl:simpurl}
\bibliographystyle{IEEEtranS}
\bibliography{references}

\end{document}

